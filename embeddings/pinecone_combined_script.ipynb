{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "173a84e7-2435-4d9e-9630-de1ff675e4b2",
   "metadata": {},
   "source": [
    "# Create Pinecone.io index from documents\n",
    "- Converts the document extracts from the document preprocessing pipeline into embeddings,\n",
    "  and places them into a Pinecone index\n",
    "- The embedding process will be very slow on a CPU instance and may crash. It is recommended\n",
    "  to use a GPU instance like ml.g4dn.xlarge\n",
    "  \n",
    "## Recommended setup\n",
    "- *Necessary*: Use Data Science 2.0 kernel, or any kernel with conda and python >= 3.8\n",
    "- When computing embeddings: Instance with at least 1 gpu, eg. ml.g4dn.xlarge\n",
    "- When using precomputed embeddings, ml.t3.medium is sufficient\n",
    "- If not using GPU, set the gpu_available variable in the first cell to False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4abcc3-2b57-455a-a4dc-32a34ebfd17f",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33abb6-710f-46b8-9519-8f7bb19ce61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set compute_embeddings to true if you need to recompute the embeddings\n",
    "# Otherwise, downloads precomputed embeddings from s3\n",
    "compute_embeddings = False \n",
    "# Set clear_index to true to clear any existing table before inserting documents\n",
    "clear_index = True\n",
    "# Set gpu_available to true when using a gpu instance, especially when computing embeddings\n",
    "gpu_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73a9cd6-23ab-42c5-b1c7-6643fa8d3645",
   "metadata": {},
   "source": [
    "## Install prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe800bb-3347-4980-98fd-891759754592",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if not gpu_available:\n",
    "    !pip install torch --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d6c77-0643-45bb-bc2e-be5720ef0f0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Call Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a933d19-252f-4072-8964-e124d05558cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = []\n",
    "args.append('--compute_embeddings' if compute_embeddings else '--no-compute_embeddings')\n",
    "args.append('--clear_index' if clear_index else '--no-clear_index')\n",
    "args.append('--gpu_available' if gpu_available else '--no-gpu_available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e0db78-9867-44e0-9390-5c088fb8f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pinecone_combined_script.py {' '.join(args)}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
