{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092de179-543f-40cb-a5b4-7647ae41d7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --quiet -U langchain langchain-community langchain-aws langchain-core pgvector\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import psycopg2\n",
    "import ast\n",
    "import pgvector\n",
    "import math\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "import boto3\n",
    "from langchain_community.embeddings.bedrock import BedrockEmbeddings\n",
    "from langchain_aws import BedrockLLM\n",
    "import time\n",
    "\n",
    "print(\"Imported and installed dependencies!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7035688a",
   "metadata": {},
   "source": [
    "For now, we are going to simply read the CSV file on the server. Look at other notebook on how to get CSV file from S3 Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43cbded-be92-47c6-a2ec-3019bfcf15b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load your CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('website_extracts_server_side.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2873ad0f-eb72-4c25-bcbc-3bc1f190274d",
   "metadata": {},
   "source": [
    "Need to create our own CSV file with URL and text columns only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd079d5-d4a8-4f8e-bba0-16212e6a8b27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only the columns we want\n",
    "selected_columns_df = df[['doc_id', 'url', 'parent_titles', 'titles', 'text', 'links']]\n",
    "\n",
    "# Remove rows where 'text' is null\n",
    "selected_columns_df = selected_columns_df.dropna(subset=['text'])\n",
    "\n",
    "# Function to transform links dictionary to list of URLs\n",
    "def transform_links(links_str):\n",
    "    try:\n",
    "        links_dict = ast.literal_eval(links_str)\n",
    "        urls_list = [url for url, _ in links_dict.values()]\n",
    "        return urls_list\n",
    "    except (SyntaxError, ValueError):\n",
    "        return []\n",
    "\n",
    "# Apply the transformation to the 'links' column\n",
    "selected_columns_df['links'] = selected_columns_df['links'].apply(transform_links)\n",
    "\n",
    "# Modify the titles column to include parent_titles followed by titles\n",
    "def combine_titles(row):\n",
    "    try:\n",
    "        # Parse parent_titles if it is not NaN\n",
    "        parent_titles = ast.literal_eval(row['parent_titles']) if pd.notna(row['parent_titles']) else []\n",
    "\n",
    "        # Parse titles if it is not NaN\n",
    "        titles = ast.literal_eval(row['titles']) if pd.notna(row['titles']) else []\n",
    "\n",
    "        # Remove the first element if it's an empty string\n",
    "        if titles and titles[0] == '':\n",
    "            titles = titles[1:]\n",
    "\n",
    "        # Combine parent_titles and titles, ensuring no duplication if the last of parent_titles is the first of titles\n",
    "        if parent_titles and titles:\n",
    "            combined_titles = parent_titles + titles if parent_titles[-1] != titles[0] else parent_titles + titles[1:]\n",
    "        else:\n",
    "            combined_titles = parent_titles + titles\n",
    "\n",
    "        return combined_titles\n",
    "    except (SyntaxError, ValueError):\n",
    "        # Return the original titles if there's an error\n",
    "        return row['titles']\n",
    "\n",
    "# Apply the combine_titles function to the 'titles' column\n",
    "selected_columns_df['titles'] = selected_columns_df.apply(combine_titles, axis=1)\n",
    "\n",
    "# Define the path for the new CSV file\n",
    "new_file_path = 'moded_1.csv'\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(new_file_path):\n",
    "    # Save the new CSV file\n",
    "    selected_columns_df.to_csv(new_file_path, index=False)\n",
    "    print(f\"New CSV file created at: {new_file_path}\")\n",
    "else:\n",
    "    print(f\"CSV file already exists at: {new_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b16238-5950-4034-8dbc-c9fcb6eec9df",
   "metadata": {},
   "source": [
    "Sanity Check to count how many rows with null \"text\" values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625dda39-a482-45ef-8584-69c49014c969",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "check = pd.read_csv('website_extracts_server_side.csv')\n",
    "\n",
    "# Count the number of rows with null values in the 'text' column\n",
    "null_text_count = check['text'].isna().sum()\n",
    "print(f\"Number of rows with null values in the 'text' column: {null_text_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dbcb99-0309-4150-891c-ba0e94f96724",
   "metadata": {},
   "source": [
    "For each row of the moded.csv file, we will create vector embeddings using the Amazon Titan Embeddings model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63509e9-91f0-47af-bcb5-8f7aa056a250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert query into embedding\n",
    "def get_bedrock_embeddings(input_text, model_id=\"amazon.titan-embed-text-v2:0\", region_name=\"us-west-2\"):\n",
    "    # Initialize the boto3 client for Bedrock\n",
    "    bedrock = boto3.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    # Prepare the prompt and request body\n",
    "    body = json.dumps({\n",
    "        \"inputText\": input_text,\n",
    "        \"dimensions\": 1024,\n",
    "        \"normalize\": True\n",
    "    })\n",
    "\n",
    "    # Set the model ID and content type\n",
    "    accept = \"*/*\"\n",
    "    content_type = \"application/json\"\n",
    "\n",
    "    # Invoke the Bedrock model to get embeddings\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body,\n",
    "        modelId=model_id,\n",
    "        accept=accept,\n",
    "        contentType=content_type\n",
    "    )\n",
    "\n",
    "    # Read and parse the response\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    embedding = response_body.get('embedding')\n",
    "\n",
    "    return embedding\n",
    "\n",
    "if not os.path.exists('moded_with_embeddings_1.csv'):\n",
    "    # Load the CSV file\n",
    "    file_path = 'moded.csv'\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Initialize the Bedrock Embeddings model\n",
    "    # embeddings = BedrockEmbeddings()\n",
    "\n",
    "    # Initialize lists to store the embeddings\n",
    "    text_embeddings_list = []\n",
    "    title_embeddings_list = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in data.iterrows():\n",
    "        # Get text and titles\n",
    "        text = row['text']\n",
    "\n",
    "        titles = \" \".join(ast.literal_eval(row['titles']))  # Convert titles list to a single string\n",
    "\n",
    "        # Generate the embedding for text if it's not empty\n",
    "        if text.strip():\n",
    "            text_embedding = get_bedrock_embeddings(text)\n",
    "        else:\n",
    "            text_embedding = []  # Or some default value\n",
    "        text_embeddings_list.append(text_embedding)\n",
    "\n",
    "        # Generate the embedding for titles if it's not empty\n",
    "        if titles.strip():\n",
    "            title_embedding = get_bedrock_embeddings(titles)\n",
    "        else:\n",
    "            title_embedding = []  # Or some default value\n",
    "        title_embeddings_list.append(title_embedding)\n",
    "\n",
    "        if (index + 1) % 500 == 0:\n",
    "            print(f\"Processed {index + 1}/{len(data)} rows\")\n",
    "\n",
    "    # Add the embeddings to the DataFrame\n",
    "    data['text_embedding'] = text_embeddings_list\n",
    "    data['title_embedding'] = title_embeddings_list\n",
    "\n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    data.to_csv('moded_with_embeddings_1.csv', index=False)\n",
    "else:\n",
    "    print(\"moded_with_embeddings already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f92db4-b4c8-44b3-96f1-285550950d14",
   "metadata": {},
   "source": [
    "Sanity check to see if CSV file with embeddings has correct data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96703df-dc22-4025-9f02-9c7598358373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the CSV file with embeddings\n",
    "file_path_with_embeddings = 'moded_with_embeddings_1.csv'\n",
    "data_with_embeddings = pd.read_csv(file_path_with_embeddings)\n",
    "\n",
    "# Perform the sanity check to count the number of rows\n",
    "number_of_rows = len(data_with_embeddings)\n",
    "\n",
    "print(f\"The number of rows in the 'moded_with_embeddings.csv' file is: {number_of_rows}\")\n",
    "\n",
    "# Print the first row of the CSV file\n",
    "first_row = data_with_embeddings.iloc[0]\n",
    "print(\"The first row in the 'moded_with_embeddings.csv' file is:\")\n",
    "print(first_row.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc3dccf-1311-4401-9c60-88ecd731b9b9",
   "metadata": {},
   "source": [
    "Connect to RDS instance and install vector extension if not already there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df89308-971e-4aae-9b31-94a5d903af8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the connection parameters\n",
    "connection_params = {\n",
    "    \"your-database-parameters\"\n",
    "}\n",
    "\n",
    "# Create the connection string\n",
    "connection_string = \" \".join([f\"{key}={value}\" for key, value in connection_params.items()])\n",
    "\n",
    "print(\"Connection string:\", connection_string)\n",
    "\n",
    "# Connect to PostgreSQL database in Timescale using connection string\n",
    "conn = psycopg2.connect(connection_string)\n",
    "cur = conn.cursor()\n",
    "\n",
    "#install pgvector\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\");\n",
    "conn.commit()\n",
    "\n",
    "print(\"Connected to RDS instance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d05663-9c20-42f3-8b4b-2f383d14485e",
   "metadata": {},
   "source": [
    "Registers the vector type with psycopg2, enabling the handling of vector data types within Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "548ada98-4789-453b-9194-365558f89ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Register the vector type with psycopg2\n",
    "register_vector(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2695b919-d8ed-4ce4-95f7-238a07f4e001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to terminate process holding the lock\n",
    "def terminate_locking_process(table_name):\n",
    "    get_pid_query = f\"\"\"\n",
    "    SELECT pid\n",
    "    FROM pg_locks l\n",
    "    JOIN pg_class t ON l.relation = t.oid AND t.relkind = 'r'\n",
    "    WHERE t.relname = '{table_name}';\n",
    "    \"\"\"\n",
    "    cur.execute(get_pid_query)\n",
    "    locking_process = cur.fetchone()\n",
    "    if locking_process:\n",
    "        pid = locking_process[0]\n",
    "        terminate_query = f\"SELECT pg_terminate_backend({pid});\"\n",
    "        cur.execute(terminate_query)\n",
    "        conn.commit()\n",
    "        print(f\"Terminated process {pid} holding lock on {table_name}.\")\n",
    "\n",
    "# Drop the table if it already exists\n",
    "drop_table_command = \"DROP TABLE IF EXISTS phase_2_embeddings;\"\n",
    "\n",
    "try:\n",
    "    # Terminate the process holding the lock if any\n",
    "    terminate_locking_process('phase_2_embeddings')\n",
    "\n",
    "    # Drop the table if it exists\n",
    "    cur.execute(drop_table_command)\n",
    "    conn.commit()\n",
    "    print(\"Table dropped if it existed.\")\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Error creating embeddings table: {e}\")\n",
    "    conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd234fe-226a-470d-b22b-3a24e8af5b99",
   "metadata": {},
   "source": [
    "Create our vector table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4dc1b8-6aad-4092-9438-91e3fee4d113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create table to store embeddings and metadata\n",
    "table_create_command = \"\"\"\n",
    "CREATE TABLE phase_2_embeddings (\n",
    "            id bigserial primary key,\n",
    "            doc_id text,\n",
    "            url text,\n",
    "            titles jsonb,\n",
    "            text text,\n",
    "            links jsonb,\n",
    "            text_embedding vector(1024),\n",
    "            title_embedding vector(1024)\n",
    "            );\n",
    "            \"\"\"\n",
    "\n",
    "cur.execute(table_create_command)\n",
    "cur.close()\n",
    "conn.commit()\n",
    "\n",
    "print(\"Table created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1ae966-99d0-42d4-a6a6-91db8b4671d0",
   "metadata": {},
   "source": [
    "Populate phase_2_embeddings table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82667d8d-fcab-4e65-b0ad-16d8b4937808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the CSV file with embeddings\n",
    "print(\"Loading the CSV file...\")\n",
    "file_path_with_embeddings = 'moded_with_embeddings_1.csv'\n",
    "data_with_embeddings = pd.read_csv(file_path_with_embeddings)\n",
    "\n",
    "# Check the type of the embedding columns\n",
    "text_embedding_type = type(first_row['text_embedding'])\n",
    "title_embedding_type = type(first_row['title_embedding'])\n",
    "print(f\"The type of the text_embedding column is: {text_embedding_type}\")\n",
    "print(f\"The type of the title_embedding column is: {title_embedding_type}\")\n",
    "\n",
    "# Function to convert string representation of list to numpy array\n",
    "def parse_embedding(embedding_str):\n",
    "    return np.array(eval(embedding_str))\n",
    "\n",
    "# Apply the function to the embedding column if it's a string\n",
    "if isinstance(first_row['text_embedding'], str):\n",
    "    print(\"Converting the text_embedding column to numpy arrays...\")\n",
    "    data_with_embeddings['text_embedding'] = data_with_embeddings['text_embedding'].apply(parse_embedding)\n",
    "    print(\"Conversion complete.\")\n",
    "else:\n",
    "    print(\"Text Embeddings are not strings, they are a list of floats\")\n",
    "\n",
    "if isinstance(first_row['title_embedding'], str):\n",
    "    print(\"Converting the title_embedding column to numpy arrays...\")\n",
    "    data_with_embeddings['title_embedding'] = data_with_embeddings['title_embedding'].apply(parse_embedding)\n",
    "    print(\"Conversion complete.\")\n",
    "else:\n",
    "    print(\"Title Embeddings are not strings, they are a list of floats\")\n",
    "\n",
    "# Verify the conversion\n",
    "first_row_converted = data_with_embeddings.iloc[0]\n",
    "print(\"The first row after converting the 'embedding' column:\")\n",
    "print(f\"The first row after converting the 'text_embedding' and 'title_embedding' columns:\\n{first_row_converted.to_dict()}\")\n",
    "\n",
    "# Convert 'titles' and 'links' columns to JSON format\n",
    "data_with_embeddings['titles'] = data_with_embeddings['titles'].apply(json.dumps)\n",
    "data_with_embeddings['links'] = data_with_embeddings['links'].apply(json.dumps)\n",
    "\n",
    "# Function to ensure embeddings are lists, not empty, and pad with zeros to the correct dimensionality\n",
    "def ensure_list_and_pad_embedding(embedding, expected_dim=1024):\n",
    "    if isinstance(embedding, np.ndarray):\n",
    "        embedding = embedding.tolist()\n",
    "    if not embedding:\n",
    "        embedding = [0] * expected_dim  # Replace empty embeddings with a list of zeros of the correct dimensionality\n",
    "    elif len(embedding) < expected_dim:\n",
    "        embedding.extend([0] * (expected_dim - len(embedding)))  # Pad with zeros\n",
    "    return embedding\n",
    "\n",
    "data_with_embeddings['text_embedding'] = data_with_embeddings['text_embedding'].apply(ensure_list_and_pad_embedding)\n",
    "data_with_embeddings['title_embedding'] = data_with_embeddings['title_embedding'].apply(ensure_list_and_pad_embedding)\n",
    "\n",
    "# Prepare the list of tuples for insertion in batches\n",
    "batch_size = 500  # Set a smaller batch size\n",
    "total_rows = len(data_with_embeddings)\n",
    "num_batches = (total_rows // batch_size) + 1\n",
    "\n",
    "print(f\"Total rows: {total_rows}, Batch size: {batch_size}, Number of batches: {num_batches}\")\n",
    "\n",
    "# Use execute_values to perform batch insertion\n",
    "for batch in range(num_batches):\n",
    "    start_idx = batch * batch_size\n",
    "    end_idx = min(start_idx + batch_size, total_rows)\n",
    "    batch_data = data_with_embeddings.iloc[start_idx:end_idx]\n",
    "\n",
    "    data_list = [(row['doc_id'],\n",
    "                  row['url'],\n",
    "                  row['titles'],\n",
    "                  row['text'],\n",
    "                  row['links'],\n",
    "                  row['text_embedding'],\n",
    "                  row['title_embedding']) for index, row in batch_data.iterrows()]\n",
    "\n",
    "    print(f\"Inserting batch {batch + 1}/{num_batches}...\")\n",
    "\n",
    "    try:\n",
    "        conn.rollback()\n",
    "        cur = conn.cursor()\n",
    "        execute_values(cur, \"INSERT INTO phase_2_embeddings (doc_id, url, titles, text, links, text_embedding, title_embedding) VALUES %s\", data_list)\n",
    "    except Exception as e:\n",
    "        print(f\"Error when populating table in batch {batch + 1}: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "    # Commit after each batch\n",
    "    conn.commit()\n",
    "    print(f\"Batch {batch + 1}/{num_batches} insertion complete!\")\n",
    "\n",
    "print(\"All batches inserted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c3c52a-dd5d-400d-938c-a9e5c855546b",
   "metadata": {},
   "source": [
    "Perform sanity checks on embeddings table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7493959-c29b-4ab0-aafd-fcbceb96c3ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "num_records = 0\n",
    "try:\n",
    "    cur.execute(\"SELECT COUNT(*) as cnt FROM phase_2_embeddings;\")\n",
    "    num_records = cur.fetchone()[0]\n",
    "    print(\"Number of vector records in table: \", num_records,\"\\n\")\n",
    "except:\n",
    "    print(\"Error when counting number of rows in embeddings table!\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a3eee9-dc25-4065-8aff-45c0086b2410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "try:\n",
    "    # print the first record in the table, for sanity-checking\n",
    "    cur.execute(\"SELECT * FROM phase_2_embeddings LIMIT 1;\")\n",
    "    records = cur.fetchall()\n",
    "    print(\"First record in table: \", records)\n",
    "except:\n",
    "    print(\"Error when printing first row in embeddings table!\")\n",
    "    conn.rollback()\n",
    "finally:\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f750a79-6854-476c-966e-b7a3efeaca19",
   "metadata": {},
   "source": [
    "Apply Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c2d50-f3af-4daf-8a29-f1de243e82fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drops existing indexes on the embedding column\n",
    "def drop_existing_indexes():\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT indexname \n",
    "            FROM pg_indexes \n",
    "            WHERE tablename = 'phase_2_embeddings' \n",
    "            AND indexdef LIKE '%embedding%' \n",
    "            AND indexdef NOT LIKE '%pkey%';\n",
    "        \"\"\")\n",
    "        indexes = cur.fetchall()\n",
    "        for index in indexes:\n",
    "            cur.execute(f\"DROP INDEX IF EXISTS {index[0]};\")\n",
    "        conn.commit()\n",
    "        print(\"Dropped existing indexes on embedding column!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error dropping existing indexes:\", e)\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "\n",
    "# Create an index on the data for faster retrieval\n",
    "def create_index(index_method, distance_measure):\n",
    "    drop_existing_indexes()\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        if index_method == 'hnsw':\n",
    "            cur.execute(f'CREATE INDEX ON phase_2_embeddings USING hnsw (text_embedding {distance_measure})')\n",
    "            cur.execute(f'CREATE INDEX ON phase_2_embeddings USING hnsw (title_embedding {distance_measure})')\n",
    "        elif index_method == 'ivfflat':\n",
    "            num_lists = num_records / 1000\n",
    "            if num_lists < 10:\n",
    "                num_lists = 10\n",
    "            if num_records > 1000000:\n",
    "                num_lists = math.sqrt(num_records)\n",
    "\n",
    "            cur.execute(f'CREATE INDEX ON phase_2_embeddings USING ivfflat (text_embedding {distance_measure}) WITH (lists = {num_lists});')\n",
    "            cur.execute(f'CREATE INDEX ON phase_2_embeddings USING ivfflat (title_embedding {distance_measure}) WITH (lists = {num_lists});')\n",
    "\n",
    "        conn.commit()\n",
    "        print(\"Created Index!\")\n",
    "    except:\n",
    "        print(\"Error when indexing embeddings table!\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "\n",
    "create_index('hnsw', 'vector_l2_ops')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542caf34-915e-42ae-9160-45b456df6b28",
   "metadata": {},
   "source": [
    "Sanity Check to see if index is on embeddings table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab888703-33bd-40a4-94a8-2752ce35f099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform sanity check to print all indexes on phase_2_embeddings\n",
    "try:\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT indexname FROM pg_indexes WHERE tablename = 'phase_2_embeddings';\")\n",
    "    indexes = cur.fetchall()\n",
    "    print(\"Indexes on phase_2_embeddings table:\")\n",
    "    for index in indexes:\n",
    "        print(index[0])\n",
    "except Exception as e:\n",
    "    print(\"Error during sanity check:\", e)\n",
    "finally:\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136498df-f1bf-4f65-900f-61ed58a45f8f",
   "metadata": {},
   "source": [
    "Sanity Check to see details of index on embeddings table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83970c1-bc24-4681-b973-b6d235f3ae5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get details of an index\n",
    "def get_index_details(index_name):\n",
    "    index_details_query = f\"\"\"\n",
    "    SELECT indexname, indexdef\n",
    "    FROM pg_indexes\n",
    "    WHERE indexname = '{index_name}';\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(index_details_query)\n",
    "        index_details = cur.fetchone()\n",
    "        if index_details:\n",
    "            print(f\"Details of index '{index_name}':\")\n",
    "            print(f\"Index Name: {index_details[0]}\")\n",
    "            print(f\"Index Definition: {index_details[1]}\")\n",
    "        else:\n",
    "            print(f\"No details found for index '{index_name}'.\")\n",
    "    except:\n",
    "        print(\"Error when checking indexing details!\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "\n",
    "# Verify details of the created index\n",
    "get_index_details('phase_2_embeddings_text_embedding_idx')\n",
    "get_index_details('phase_2_embeddings_title_embedding_idx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e161e0e-7bd6-4882-ade8-3a7038528dcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Retrieval Step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51df0af-98a1-4d56-ad14-6334e79ccac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get most similar documents from the database\n",
    "def get_docs(query_embedding, number):\n",
    "    embedding_array = np.array(query_embedding)\n",
    "    # Register pgvector extension\n",
    "    register_vector(conn)\n",
    "    top_docs = []\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        # Get the top N most similar documents using the KNN <=> operator\n",
    "        cur.execute(\"\"\"\n",
    "                        SELECT doc_id, url, titles, text, links, text_similarity, title_similarity, (text_similarity + title_similarity) as total_similarity\n",
    "                        FROM (\n",
    "                            SELECT doc_id, url, titles, text, links, \n",
    "                                   text_embedding <=> %s AS text_similarity,\n",
    "                                   title_embedding <=> %s AS title_similarity\n",
    "                            FROM phase_2_embeddings\n",
    "                        ) sub\n",
    "                        ORDER BY total_similarity\n",
    "                        LIMIT %s\n",
    "                    \"\"\", (embedding_array, embedding_array, number))\n",
    "        results = cur.fetchall()\n",
    "        for result in results:\n",
    "            doc_dict = {\"doc_id\": result[0],\n",
    "                        \"url\": result[1],\n",
    "                        \"titles\": result[2],\n",
    "                        \"text\": result[3],\n",
    "                        \"links\": result[4],\n",
    "                        \"text_similarity\": result[5],\n",
    "                        \"title_similarity\": result[6],\n",
    "                        \"total_similarity\": result[7]}\n",
    "            top_docs.append(doc_dict)\n",
    "        cur.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error when retrieving: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "    return top_docs\n",
    "\n",
    "# Initialize the Bedrock Embeddings model\n",
    "embeddings = BedrockEmbeddings()\n",
    "\n",
    "text = \"Does physics 100 count for the arts requirement?\"\n",
    "# text = \"What are all the faculties at UBC?\"\n",
    "docs = get_docs(embeddings.embed_query(text), 5)\n",
    "for idx, doc in enumerate(docs, 1):\n",
    "    print(f\"\\nDocument {idx}:\\n{doc['doc_id']}\\n{doc['url']}\\n{doc['titles']}\\n{doc['text']}\\n{doc['links']}\\n{doc['text_similarity']}\\n{doc['title_similarity']}\\n{doc['total_similarity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6425f811-8cb9-4478-975d-ec0a64944329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get most similar documents from the database\n",
    "def get_docs(query_embedding, number, embedding_column):\n",
    "    embedding_array = np.array(query_embedding)\n",
    "    # Register pgvector extension\n",
    "    register_vector(conn)\n",
    "    top_docs = []\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        # Get the top N most similar documents using the KNN <=> operator\n",
    "        cur.execute(f\"\"\"\n",
    "                        SELECT doc_id, url, titles, text, links, {embedding_column} <=> %s AS similarity\n",
    "                        FROM phase_2_embeddings\n",
    "                        ORDER BY similarity\n",
    "                        LIMIT %s\n",
    "                    \"\"\", (embedding_array, number))\n",
    "        results = cur.fetchall()\n",
    "        for result in results:\n",
    "            doc_dict = {\"doc_id\": result[0],\n",
    "                        \"url\": result[1],\n",
    "                        \"titles\": ast.literal_eval(result[2]),\n",
    "                        \"text\": result[3],\n",
    "                        \"links\": ast.literal_eval(result[4]),\n",
    "                        \"score\": result[5]}\n",
    "            top_docs.append(doc_dict)\n",
    "        cur.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error when retrieving: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "    return top_docs\n",
    "\n",
    "def get_combined_docs(query_embedding, number):\n",
    "    text_docs = get_docs(query_embedding, number, embedding_column='text_embedding')\n",
    "    title_docs = get_docs(query_embedding, number, embedding_column='title_embedding')\n",
    "\n",
    "    # Combine documents, avoiding duplicates\n",
    "    combined_docs = {}\n",
    "    for doc in text_docs:\n",
    "        doc_id = doc['doc_id']\n",
    "        if doc_id not in combined_docs:\n",
    "            combined_docs[doc_id] = doc\n",
    "        else:\n",
    "            # Choose lower score if document already exists\n",
    "            combined_docs[doc_id]['score'] = min(combined_docs[doc_id]['score'], doc['score'])\n",
    "\n",
    "    for doc in title_docs:\n",
    "        doc_id = doc['doc_id']\n",
    "        if doc_id not in combined_docs:\n",
    "            combined_docs[doc_id] = doc\n",
    "        else:\n",
    "            # Choose lower score if document already exists\n",
    "            combined_docs[doc_id]['score'] = min(combined_docs[doc_id]['score'], doc['score'])\n",
    "\n",
    "    # Sort documents by score in ascending order (since lower score indicates higher similarity)\n",
    "    sorted_docs = sorted(combined_docs.values(), key=lambda x: x['score'])\n",
    "\n",
    "    return sorted_docs[:number]\n",
    "\n",
    "# Initialize the Bedrock Embeddings model\n",
    "embeddings = BedrockEmbeddings()\n",
    "\n",
    "text = \"Does physics 100 count for the arts requirement?\"\n",
    "# text = \"What are all the faculties at UBC?\"\n",
    "docs = get_combined_docs(embeddings.embed_query(text), 5)\n",
    "for idx, doc in enumerate(docs, 1):\n",
    "    print(f\"\\nDocument {idx}:\\n{doc['doc_id']}\\n{doc['url']}\\n{doc['titles']}\\n{doc['text']}\\n{doc['links']}\\n{doc['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89e2492-f930-45af-b11e-317e36285a4e",
   "metadata": {},
   "source": [
    "Putting everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a23a3bf-0c8f-422c-a8f9-1037c28cdfbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining Constants\n",
    "LLAMA_3_8B = \"meta.llama3-8b-instruct-v1:0\"\n",
    "LLAMA_3_70B = \"meta.llama3-70b-instruct-v1:0\"\n",
    "MISTRAL_7B = \"mistral.mistral-7b-instruct-v0:2\"\n",
    "MISTRAL_LARGE = \"mistral.mistral-large-2402-v1:0\"\n",
    "LLAMA_3_1_8B = \"meta.llama3-1-8b-instruct-v1:0\"\n",
    "LLAMA_3_1_70B = \"meta.llama3-1-70b-instruct-v1:0\"\n",
    "\n",
    "# Convert query into embedding\n",
    "def get_bedrock_embeddings(input_text, model_id=\"amazon.titan-embed-text-v2:0\", region_name=\"us-west-2\"):\n",
    "    # Initialize the boto3 client for Bedrock\n",
    "    bedrock = boto3.client(\n",
    "        service_name='bedrock-runtime',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    # Prepare the prompt and request body\n",
    "    body = json.dumps({\n",
    "        \"inputText\": input_text,\n",
    "        \"dimensions\": 1024,\n",
    "        \"normalize\": True\n",
    "    })\n",
    "\n",
    "    # Set the model ID and content type\n",
    "    accept = \"*/*\"\n",
    "    content_type = \"application/json\"\n",
    "\n",
    "    # Invoke the Bedrock model to get embeddings\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body,\n",
    "        modelId=model_id,\n",
    "        accept=accept,\n",
    "        contentType=content_type\n",
    "    )\n",
    "\n",
    "    # Read and parse the response\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    embedding = response_body.get('embedding')\n",
    "\n",
    "    # Print the embedding\n",
    "    print(embedding)\n",
    "    return embedding\n",
    "\n",
    "# Format all texts in the doc as one string when we pass prompt to LLM\n",
    "def format_docs(docs):\n",
    "    formatted_docs = \"\\n\".join([f\"Document {idx}:\\n{doc['text']}\" for idx, doc in enumerate(docs, 1)])\n",
    "    return formatted_docs\n",
    "\n",
    "# Get most similar documents from the database\n",
    "def get_docs(query_embedding, number, embedding_column):\n",
    "    embedding_array = np.array(query_embedding)\n",
    "    # Register pgvector extension\n",
    "    register_vector(conn)\n",
    "    top_docs = []\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        # Get the top N most similar documents using the KNN <=> operator\n",
    "        cur.execute(f\"\"\"\n",
    "                        SELECT doc_id, url, titles, text, links, {embedding_column} <=> %s AS similarity\n",
    "                        FROM phase_2_embeddings\n",
    "                        ORDER BY similarity\n",
    "                        LIMIT %s\n",
    "                    \"\"\", (embedding_array, number))\n",
    "        results = cur.fetchall()\n",
    "        for result in results:\n",
    "            doc_dict = {\"doc_id\": result[0],\n",
    "                        \"url\": result[1],\n",
    "                        \"titles\": ast.literal_eval(result[2]),\n",
    "                        \"text\": result[3],\n",
    "                        \"links\": ast.literal_eval(result[4]),\n",
    "                        \"score\": result[5]}\n",
    "            top_docs.append(doc_dict)\n",
    "        cur.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error when retrieving: {e}\")\n",
    "        conn.rollback()\n",
    "    finally:\n",
    "        cur.close()\n",
    "    return top_docs\n",
    "\n",
    "def get_combined_docs(query_embedding, number):\n",
    "    text_docs = get_docs(query_embedding, number, embedding_column='text_embedding')\n",
    "    title_docs = get_docs(query_embedding, number, embedding_column='title_embedding')\n",
    "\n",
    "    # Combine documents, avoiding duplicates\n",
    "    combined_docs = {}\n",
    "    for doc in text_docs:\n",
    "        doc_id = doc['doc_id']\n",
    "        if doc_id not in combined_docs:\n",
    "            combined_docs[doc_id] = doc\n",
    "        else:\n",
    "            # Choose lower score if document already exists\n",
    "            combined_docs[doc_id]['score'] = min(combined_docs[doc_id]['score'], doc['score'])\n",
    "\n",
    "    for doc in title_docs:\n",
    "        doc_id = doc['doc_id']\n",
    "        if doc_id not in combined_docs:\n",
    "            combined_docs[doc_id] = doc\n",
    "        else:\n",
    "            # Choose lower score if document already exists\n",
    "            combined_docs[doc_id]['score'] = min(combined_docs[doc_id]['score'], doc['score'])\n",
    "\n",
    "    # Sort documents by score in ascending order (since lower score indicates higher similarity)\n",
    "    sorted_docs = sorted(combined_docs.values(), key=lambda x: x['score'])\n",
    "\n",
    "    return sorted_docs\n",
    "\n",
    "# Split documents based on character limit, 8,000 tokens is roughly 32,000 characters\n",
    "def split_docs(docs, max_chars=25000):\n",
    "    total_length = len(format_docs(docs))\n",
    "    print(total_length)\n",
    "    removed_docs = []\n",
    "\n",
    "    while total_length > max_chars and docs:\n",
    "        removed_doc = docs.pop()\n",
    "        removed_docs.append(removed_doc)\n",
    "        total_length = len(format_docs(docs))\n",
    "    return {\"docs\": docs, \"removed_docs\": removed_docs}\n",
    "\n",
    "def check_if_documents_relates(docs, user_prompt, llm):\n",
    "\n",
    "    system_prompt = \"Provide a short explaination if the document is relevant to the question or not.\"\n",
    "\n",
    "    doc_relates = []\n",
    "    for doc in docs:\n",
    "        if llm.model_id == LLAMA_3_8B or llm.model_id == LLAMA_3_70B or llm.model_id == LLAMA_3_1_8B or llm.model_id == LLAMA_3_1_70B:\n",
    "            prompt = f\"\"\"\n",
    "                <|begin_of_text|>\n",
    "                <|start_header_id|>system<|end_header_id|>\n",
    "                {system_prompt}\n",
    "                <|eot_id|>\n",
    "                <|start_header_id|>question<|end_header_id|>\n",
    "                {user_prompt}\n",
    "                <|eot_id|>\n",
    "                <|start_header_id|>document<|end_header_id|>\n",
    "                {doc['text']}\n",
    "                <|eot_id|>\n",
    "                <|start_header_id|>assistant<|end_header_id|>\n",
    "                \"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"Here is a queston that a user asked: {user_prompt}.\n",
    "                Here is the text from a document: {doc['text']}.\n",
    "                {system_prompt}. Only generate one human readable answer that is concise.\n",
    "                \"\"\"\n",
    "        response = llm.invoke(prompt).strip()\n",
    "\n",
    "        doc_info = {\"doc_id\": doc['doc_id'],\n",
    "                    \"url\": doc['url'],\n",
    "                    \"titles\": doc['titles'],\n",
    "                    \"text\": doc['text'],\n",
    "                    \"links\": doc['links'],\n",
    "                    \"relate\": response}\n",
    "        doc_relates.append(doc_info)\n",
    "\n",
    "    return doc_relates\n",
    "\n",
    "def answer_prompt(user_prompt, number_of_docs):\n",
    "\n",
    "    # Record the start times\n",
    "    total_start_time = time.time()\n",
    "    answer_start_time = time.time()\n",
    "\n",
    "    # Initialize the Bedrock Embeddings model\n",
    "    # embeddings = BedrockEmbeddings()\n",
    "    embedding = get_bedrock_embeddings(user_prompt)\n",
    "\n",
    "    docs = get_combined_docs(embedding, number_of_docs)\n",
    "\n",
    "    divided_docs = split_docs(docs)\n",
    "    print(len(divided_docs[\"docs\"]))\n",
    "\n",
    "    documents = format_docs(divided_docs[\"docs\"])\n",
    "\n",
    "    # Get the LLM we want to invoke\n",
    "    llm = BedrockLLM(\n",
    "                        model_id=LLAMA_3_8B\n",
    "                    )\n",
    "\n",
    "    system_prompt = \"You are a helpful UBC student advising assistant who answers with kindness while being concise.\"\n",
    "    # system_prompt = \"You are a helpful UBC student advising assistant who answers with kindness while being concise. If the question does not relate to UBC, respond with 'IDK.'\"\n",
    "    # system_prompt = \"\"\"You are a helpful UBC student advising assistant. \n",
    "    #                    Using the documents given to you, consicely answer the user's prompt with kindness. \n",
    "    #                    If the question does not relate to UBC, respond with 'IDK.'\"\"\"\n",
    "\n",
    "    if llm.model_id == LLAMA_3_8B or llm.model_id == LLAMA_3_70B or llm.model_id == LLAMA_3_1_8B or llm.model_id == LLAMA_3_1_70B:\n",
    "        prompt = f\"\"\"\n",
    "            <|begin_of_text|>\n",
    "            <|start_header_id|>system<|end_header_id|>\n",
    "            {system_prompt}\n",
    "            <|eot_id|>\n",
    "            <|start_header_id|>user<|end_header_id|>\n",
    "            {user_prompt}\n",
    "            <|eot_id|>\n",
    "            <|start_header_id|>documents<|end_header_id|>\n",
    "            {documents}\n",
    "            <|eot_id|>\n",
    "            <|start_header_id|>assistant<|end_header_id|>\n",
    "            \"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"{system_prompt}. Provide your answer as if you are talking to a student.\n",
    "            Here is the question: {user_prompt}.\n",
    "            Here are the source documents: {documents}\n",
    "            \"\"\"\n",
    "\n",
    "    answer = llm.invoke(prompt)\n",
    "\n",
    "    # Record the end time and find duration of answer only\n",
    "    answer_end_time = time.time()\n",
    "    answer_duration = answer_end_time - answer_start_time\n",
    "\n",
    "    check_docs = check_if_documents_relates(divided_docs[\"docs\"], user_prompt, llm)\n",
    "    check_additional_docs = check_if_documents_relates(divided_docs[\"removed_docs\"], user_prompt, llm)\n",
    "\n",
    "    # Record the end time and find duration of the total time of checking over each document\n",
    "    total_end_time = time.time()\n",
    "    total_duration = total_end_time - total_start_time\n",
    "\n",
    "    return {\"answer\": answer, \"docs\": check_docs, \"additional_docs\": check_additional_docs, \"answer_time\": answer_duration, \"total_time\": total_duration}\n",
    "\n",
    "# Neatly prints dictionary returned by answer_prompt\n",
    "def neat_print(response):\n",
    "    print(f\"Answer: {response['answer']}\\n\")\n",
    "    \n",
    "    print(\"Documents:\")\n",
    "    for doc in response['docs']:\n",
    "        print(f\"doc_id: {doc['doc_id']}\")\n",
    "        print(f\"URL: {doc['url']}\")\n",
    "        print(f\"Titles: {doc['titles']}\")\n",
    "        print(f\"Text:\\n{doc['text']}\")\n",
    "        print(f\"Links:{doc['links']}\")\n",
    "        print(f\"Relevance: {doc['relate']}\")\n",
    "    \n",
    "    print(\"_________________________________________________________________________________________________________\")\n",
    "    \n",
    "    print(\"Additional Documents:\")\n",
    "    for doc in response['additional_docs']:\n",
    "        print(f\"doc_id: {doc['doc_id']}\")\n",
    "        print(f\"URL: {doc['url']}\")\n",
    "        print(f\"Titles: {doc['titles']}\")\n",
    "        print(f\"Text:\\n{doc['text']}\")\n",
    "        print(f\"Links:{doc['links']}\")\n",
    "        print(f\"Relevance: {doc['relate']}\")\n",
    "    \n",
    "    print(f\"answer_time: {response['answer_time']}\\n\")\n",
    "    print(f\"total_time: {response['total_time']}\\n\")\n",
    "\n",
    "response = answer_prompt(\"Does physics 100 count for the arts requirement?\", 5)\n",
    "\n",
    "neat_print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55303672-d4a3-40e2-bd81-5a55e0d3f74d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.040755432, 0.034010693, -0.0144222565, -0.04391254, -0.030279564, -0.017794624, 0.02138225, 0.04190347, -0.01112164, 0.025113381, 0.003157111, 0.0057402016, 0.026835442, 0.02195627, 0.027983483, -0.057115003, -0.00050002534, -0.028988017, 0.010691125, 0.03788533, -0.01937318, -0.015857307, 0.010691125, -0.009830095, -0.006816489, 0.008072158, 0.026404927, 0.011049888, 0.09930549, -0.008502673, 0.02453936, 0.009148446, -0.07749272, -0.007426386, 0.060272116, 0.052235834, 0.0027445338, -0.024108846, 0.0456346, 0.011623908, 0.025113381, -0.008215663, 0.0005785047, 0.018942665, 0.06285521, 0.0099736005, 0.07864076, 0.064003244, -0.025974412, -0.0067088604, -0.0027445338, -0.013919989, 0.020808231, 0.06371624, 0.048504703, 0.031284098, 0.0032468014, -0.0047356663, 0.06658634, -0.09586137, -0.051087793, -0.027122453, -0.0004977831, 0.03329317, -0.050513774, -0.02138225, -0.0076416433, 0.0037849455, 0.008646178, 0.0077851485, -0.013130711, -0.0067088604, -0.046208624, -0.030566573, -0.034584712, -0.0062783454, 0.038172342, 0.012700195, 0.023965342, 0.08725106, -0.058837064, 0.01226968, -0.043338522, -0.08610302, -0.03960739, -0.0058478303, -0.0028521626, -0.017292356, 0.021525756, 0.052235834, 0.03845935, 0.034584712, -0.003444121, -0.010475867, 0.04391254, -0.0370243, -0.034297705, 0.0024216475, 0.016503079, -0.014565761, -0.038172342, 0.002197421, -0.02138225, 0.08438096, 0.0370243, -0.016861841, 0.020951735, -0.008717931, -0.006385974, 0.011982671, 0.08208488, -0.008036282, -0.012413186, 0.0341542, 0.08036282, 0.026117917, 0.008574426, -0.0088614365, 0.018225139, 0.013058959, 0.034297705, 0.010978135, -0.024826372, 0.058837064, 0.04649563, 0.003731131, 0.008430921, 0.024826372, 0.008108035, -0.039033372, 0.016000811, 0.014494008, 0.027409462, 0.017579367, -0.003192987, -0.051948823, -0.010117105, 0.03874636, -0.0091125695, -0.025256887, -0.028270492, 0.000968659, -0.039894402, -0.026691938, 0.030279564, -0.027839977, 0.0072111282, 0.0042513367, -0.036593784, -0.016287822, 0.03243214, -0.0341542, 0.033436675, 0.047930684, -0.028413998, 0.025543896, -0.009184322, -0.010906382, 0.004843295, 0.027122453, -0.055679955, 0.0016413389, 0.036306776, 0.023965342, -0.02052122, -0.024108846, -0.031284098, -0.0030136057, 0.020808231, 0.015570297, -0.048504703, -0.008072158, 0.024108846, -0.026404927, 0.083232924, -0.0088614365, -0.01054762, -0.036450278, -0.026691938, -0.012484938, -0.02109524, -0.006493603, -0.001811751, 0.03444121, -0.014852772, -0.010188858, -0.0033903066, -0.000103144244, -0.0029777295, -0.003318554, -0.019947201, 0.009614837, -0.019229675, 0.045921613, -0.0427645, -0.0012736073, -0.011695661, -0.035589248, 0.02540039, -0.003749069, -0.036450278, -0.04046842, 0.034728218, 0.021669261, 0.01879916, -0.024252351, 0.00939958, -0.0427645, 0.007426386, 0.005381439, -0.0022960806, 0.032001622, -0.015068029, 0.02224328, -0.006242469, -0.049652744, 0.061133146, -0.0049868003, -0.020377716, -0.004448656, 0.013991741, -0.048791714, -0.006493603, -0.027696472, -0.06629933, -0.019803695, -0.020808231, 0.024108846, 0.021812765, 0.028413998, 0.030997088, 0.045060582, -0.047643673, 0.020808231, 0.04305151, -0.0011570094, -0.020951735, 0.08725106, 0.00014911071, -0.010045352, -0.0051661814, 0.09299126, 0.036019765, 0.010906382, 0.0740486, -0.009830095, -0.010762878, 0.006924118, -0.06687335, -0.06716036, 0.04219048, -0.024826372, -0.009184322, 0.011336898, -0.024969876, 0.007821024, 0.00044845324, 0.011623908, 0.013058959, -0.019516686, -0.022530291, 0.06285521, -0.020377716, 0.0012646382, 0.0073905094, 0.012771948, -0.034010693, -0.052809853, 0.005632573, 0.027409462, -0.010117105, 0.0036414403, 0.026691938, 0.026835442, -0.030566573, -0.053383876, 0.014996276, -0.0010314424, -0.033436675, -0.058263045, -0.03845935, 0.022673797, 0.04649563, -0.011839165, 0.06974345, 0.020951735, -0.0099736005, -0.01879916, 0.048791714, -0.01112164, 0.0009910817, 0.008610303, -0.024395857, -0.028844513, 0.024969876, 0.0041975225, -0.018368645, -0.0066012316, 0.04190347, 0.0018476273, -0.017148852, 0.0012287619, 0.052809853, -0.02367833, 0.04190347, -0.005524944, -0.014924524, -0.021525756, 0.009901848, 0.012413186, 0.033149663, 0.013919989, 0.008287416, -0.01851215, 0.018655654, 0.012413186, -0.017794624, -0.0170771, -0.014996276, -0.03932038, -0.00853855, 0.0022512353, 0.0038387598, 0.01765112, -0.024969876, -0.04104244, 0.0228173, -0.0025651525, 0.033723682, 0.018942665, 0.03845935, -0.023391321, -0.055966966, 0.020808231, -0.07175252, -0.031140594, 0.032288633, 0.036593784, 0.018153388, -0.008430921, -0.045921613, -0.014852772, 0.017794624, -0.026835442, -0.04219048, 0.017866377, 0.012484938, -0.025543896, -0.03329317, 0.009758343, -0.00086551474, 0.04391254, -0.036450278, -0.014135246, -0.04132945, 0.01226968, -0.024395857, -0.0007444324, 0.022673797, 0.04448656, -0.005632573, -0.0039284504, -0.027839977, -0.02224328, -0.047643673, -0.0144222565, -0.06342923, -0.012556691, 0.06687335, 0.049652744, -0.026835442, -0.018655654, -0.058837064, 0.01851215, 0.000556082, 0.01112164, -0.008395045, 0.015283287, -0.016503079, 0.031714614, -0.034297705, 0.027983483, 0.00153371, 0.009830095, -0.0035696877, 0.061994176, -0.01112164, -0.02367833, -0.06515129, -0.039894402, -0.014494008, 0.010188858, 0.03845935, -0.018368645, 0.0027445338, 0.007749272, -0.03759832, 0.03587626, -0.013345969, -0.052809853, -0.028844513, 0.05080078, 0.054531913, -0.04448656, -0.025113381, -0.006314222, 0.018942665, -0.0045562848, 0.033723682, 0.04104244, -0.02138225, 0.00796453, 0.008108035, 0.014135246, 0.0014529885, 0.03185812, 0.01054762, -0.021669261, 0.047930684, 0.012771948, 0.055679955, 0.014781019, 0.012556691, 0.01140865, -0.0017848439, 0.0769187, 0.018009882, 0.0024216475, -0.0012825762, -0.04391254, 0.044199552, -0.016431326, -0.01621607, -0.0058478303, -0.017005347, 0.0031032965, 0.021812765, -0.059411086, -0.07089149, 0.04391254, -0.029705543, 0.006924118, 0.02109524, -0.027983483, 0.03587626, 0.020951735, 0.028413998, 0.007749272, -0.010978135, 0.024969876, 0.048504703, 0.023391321, 0.0038387598, -0.0341542, 0.0059195827, -0.061994176, 0.03960739, -0.019947201, -0.057689026, 0.014996276, -0.012126176, 0.047643673, -0.061133146, -0.040755432, -0.018153388, -0.011982671, 0.054531913, 0.055105936, 0.013274216, -0.013776484, 0.0456346, 0.013561226, 0.074622616, 0.01054762, 0.0017399986, 0.014206999, 0.01226968, -0.04219048, -0.0013363906, -0.02195627, -0.0031391727, -0.04132945, -0.03358018, 0.01679009, 0.030136058, 0.011336898, 0.043338522, -0.008287416, -0.062281188, -0.023104312, 0.053383876, 0.022673797, 0.0020180396, 0.0006368036, 0.011982671, -0.010834631, -0.028413998, -0.044199552, -0.038172342, 0.08208488, 0.021525756, 0.0024934001, 0.02052122, -0.051374804, -0.0069599943, -0.0067088604, -0.0042154603, 0.0010852568, -0.07519664, -0.03329317, -0.010906382, 0.028988017, 0.0059913355, 0.005811954, 0.032862652, 0.01851215, 0.018296892, -0.009758343, -0.017148852, 0.051087793, 0.00556082, 0.022099776, -0.0059913355, -0.015068029, 0.07347458, -0.0073905094, 0.025687402, -0.008143911, -0.0036773165, 0.013632978, 0.00527381, -0.033006158, 0.022960806, -0.016144317, 0.05080078, -0.008789684, -0.002349895, -0.037311308, -0.033149663, 0.0046280376, 0.0047356663, 0.032145128, 0.046782643, 0.013704731, -0.026835442, -0.048791714, -0.020951735, 0.04907872, -0.013704731, -0.053670883, 0.015139782, -0.0068523656, 0.026548432, 0.006780613, -0.02109524, -0.011552156, -0.017435862, 0.0427645, 0.0049150474, -0.027839977, -0.0028521626, 0.017148852, -0.010404116, -0.0026727812, 0.030279564, -0.011623908, 0.009184322, 0.008646178, -0.015642049, 0.0049150474, -0.0370243, 0.010906382, 0.0040002028, 0.0024575237, -0.04104244, 0.018655654, 0.01851215, 0.0099736005, 0.012771948, -0.017148852, -0.0054890676, -0.0043051513, 0.009256075, 0.015498544, -0.045921613, 0.005524944, 0.034728218, -0.03358018, 0.013130711, 0.021669261, 0.032001622, -0.018655654, -0.0050585526, -0.024252351, 0.029562037, -0.020808231, 0.011552156, -0.04821769, -0.0170771, 0.0034979354, 0.023247816, -0.0069599943, -0.038172342, -0.048791714, -0.028701007, -0.020951735, -0.010691125, 0.012771948, 0.016000811, 0.06285521, 0.056540985, 0.0072828806, -0.014135246, -0.011265146, 0.04046842, 0.07146551, -0.050226763, -0.031427603, 0.046782643, -0.007354633, -0.024252351, 0.016287822, 0.04993975, 0.009327827, 0.00306742, -0.040755432, 0.041616462, 0.010188858, 0.06285521, 0.00853855, -0.0051661814, -0.017794624, 0.00022086322, -0.0035517497, -0.007821024, -0.067447364, -0.04448656, 0.03845935, 0.06658634, -0.04993975, 0.0020270087, 0.007354633, -0.008359169, -0.024108846, -0.00882556, -0.054244906, -0.026548432, 0.015498544, 0.013202463, -0.022960806, -0.047643673, -0.026691938, -0.055679955, -0.044199552, -0.039894402, -0.009184322, -0.0054890676, -0.03673729, 0.004843295, -0.039894402, -0.04046842, -0.033723682, 0.017005347, 0.0016503079, -0.0370243, -0.018225139, -0.002349895, -0.00023543795, -0.0033006158, -0.01765112, 0.04104244, -0.028413998, 0.030136058, 0.017794624, -0.034297705, -0.027983483, 0.055679955, -0.012054423, 0.0041078315, -0.059985105, -0.007462262, -0.014494008, -0.017866377, -0.021812765, 0.027409462, -0.030710079, 0.026404927, -0.019803695, -0.0041078315, 0.028413998, 0.037311308, 0.034728218, 0.008395045, -0.014278751, 0.010906382, -0.0024934001, 0.013417721, -0.00939958, 0.01140865, -0.016287822, -0.026404927, 0.100453526, -0.030710079, 0.0020897922, 0.0370243, 0.028988017, -0.008933188, 0.035158735, -0.01966019, -0.029562037, 0.0012108238, -0.03932038, 0.029992552, -0.012843701, 0.000690618, -0.033436675, -0.029705543, 0.025974412, 0.059698097, -0.039894402, 0.034297705, 0.018942665, 0.02109524, -0.025543896, -0.034010693, 0.018942665, -0.026691938, -0.004448656, -0.024826372, 0.0038566978, -0.012054423, 0.0058478303, -0.000556082, 0.017435862, -0.01765112, 0.018296892, -0.012484938, 0.034584712, -0.032862652, -0.010978135, -0.009256075, -0.029418532, -0.017364109, -0.039033372, -0.032575645, -0.012843701, 0.0024216475, 0.0024395857, 0.009148446, -0.027839977, -0.04907872, 0.0066729845, 0.005453191, 0.008215663, 0.017579367, -0.05080078, 0.029418532, 0.043338522, 0.004950924, -0.059698097, 0.018655654, 0.0012736073, 0.033006158, 0.0025651525, -0.000488814, 0.027696472, 0.0017041223, -0.031284098, 0.019086171, -0.04190347, -0.0370243, -0.01140865, -0.0064218505, -0.025974412, 0.009830095, -0.014852772, 0.07577066, 0.0052379337, -0.006385974, 0.009184322, 0.008143911, -0.01026061, -0.0017399986, 0.02195627, 0.055679955, 0.0091125695, 0.01140865, -0.003964327, 0.026117917, 0.034010693, 0.010117105, -0.04018141, 0.031714614, -0.04190347, -0.03530224, -0.015355039, -0.025687402, 0.035445746, -0.00078479317, -0.01851215, 0.017435862, -0.0427645, -0.050513774, -0.031714614, -0.032575645, 0.08610302, 0.028844513, -0.008072158, -0.03932038, 0.013058959, -0.006242469, -0.009901848, 0.03932038, 0.019086171, -0.029849049, -0.029131522, 0.022099776, 0.0099736005, -0.015642049, -0.024395857, -0.006924118, 0.020664725, -9.529632e-05, 0.0015875244, -0.0067088604, 0.035732754, 0.017794624, 0.007928654, -0.00033409765, -0.007067623, -0.027265957, 0.004538347, 0.046782643, 0.003964327, -0.02224328, 0.07031747, -0.010691125, 0.019947201, 0.017794624, 0.057402015, 0.027839977, -0.029131522, -0.048791714, -0.0064218505, 0.0062783454, 0.004950924, -0.04448656, 0.057976034, 0.0341542, -0.044199552, -0.03960739, 0.0370243, 0.021669261, 0.048504703, 0.02224328, -0.01937318, 0.026261423, -0.016574832, -0.019086171, -0.07146551, -0.013704731, 0.039894402, -0.04190347, -0.064290255, -0.049652744, -0.005776078, 0.020377716, 0.02109524, 0.013704731, -0.048504703, 0.0054890676, -0.051087793, -0.00939958, -0.013776484, 0.026404927, -0.090121165, -0.0456346, -0.06371624, -0.088399105, 0.032575645, -0.0072111282, 0.05080078, -0.00968659, 0.02109524, 0.019086171, -0.09643538, -0.02453936, 0.016000811, -0.023821836, 0.017364109, -0.0009327828, 0.0228173, -0.085529, -0.019803695, 0.047930684, -0.0006951025, 0.023821836, -0.0012736073, 0.02052122, 0.045921613, 0.018368645, -0.069169424, 0.031714614, -0.006637108, 0.01026061, 0.013130711, -0.004538347, -0.013919989, 0.07060448, 0.006924118, 0.005381439, 0.0015606172, 0.009148446, 0.0023319568, -0.003874636, 0.055392943, -0.011623908, -0.012771948, 0.0068523656, -0.06888242, 0.00086551474, -0.04219048, -0.0033006158, 0.00882556, 0.0049150474, 0.028988017, 0.0010314424, -0.033149663, -0.010691125, 0.028413998, 0.036306776, -0.0427645, -0.030566573, -0.00040136566, 0.0065294793, -0.034010693, -0.040755432, 0.0427645, -0.013848236, 0.03932038, 0.016072564, -0.040755432, -0.04448656, 0.028557502, 0.016861841, 0.017292356, -0.005776078, 0.019803695, 0.034584712, 0.008646178, 0.064290255, -0.0032109253, 0.034728218, 0.030710079, -0.012556691, 0.034871724, 0.017435862, -0.026261423, -0.02138225, -0.041616462, 0.047930684, 0.028557502, -0.026835442, 0.023247816, -0.023247816, 0.012413186, -0.0063500977, 0.00556082, 0.0020001014, 0.01140865, 0.002601029, 0.010332363, 0.04219048, 0.0121979285, 0.0041078315, 0.021812765, -0.0004910563, -0.011623908, -0.029562037, 0.0018027821, -0.074622616, -0.0046639135, -0.004018141, 0.025974412, -0.018225139, 0.011265146, -0.03358018, -0.030566573, -0.0370243, 0.0228173, -0.005776078, -0.017148852, -0.012556691, 0.01879916, -0.00220639, 0.026691938, -0.013202463, -0.020951735, -0.01140865, -0.019803695, 0.046782643, 0.025974412, -0.017005347, 0.007462262, 0.025687402, -0.024826372, -0.0099736005, -0.02023421, -0.03932038, -0.018368645, -0.027409462, 0.032575645, 0.0038208216, 0.093565285, 0.04018141, 0.022099776, 0.047643673, 0.0064218505, 0.032575645, -0.012556691, 0.04305151, -0.006314222, -0.030136058, 0.00527381]\n",
      "5834\n",
      "10\n",
      "Answer:  The Faculty of Applied Sciences at UBC offers a variety of specializations, including:\n",
      "\n",
      "1. Biomedical Engineering\n",
      "2. Chemical Engineering\n",
      "3. Chemical and Biological Engineering\n",
      "4. Civil Engineering\n",
      "5. Computer Engineering\n",
      "6. Electrical Engineering\n",
      "7. Engineering Physics\n",
      "8. Environmental Engineering\n",
      "9. Geological Engineering\n",
      "10. Integrated Engineering\n",
      "11. Manufacturing Engineering\n",
      "12. Materials Engineering\n",
      "13. Mechanical Engineering\n",
      "14. Mining Engineering\n",
      "15. Master of Engineering Leadership in Advanced Materials Manufacturing\n",
      "16. Master of Engineering Leadership in Clean Energy Engineering\n",
      "17. Master of Engineering Leadership in Dependable Software Systems\n",
      "18. Master of Engineering Leadership in High Performance Buildings\n",
      "19. Master of Engineering Leadership in Integrated Water Management\n",
      "20. Master of Engineering Leadership in Naval Architecture and Marine Engineering\n",
      "21. Master of Engineering Leadership in Sustainable Process Engineering\n",
      "22. Master of Engineering Leadership in Urban Systems\n",
      "23. Master of Health Leadership and Policy in Clinical Education\n",
      "24. Master of Health Leadership and Policy in Seniors Care\n",
      "\n",
      "Please note that this list may not be exhaustive, and there may be additional specializations available. I recommend checking the UBC Academic Calendar or the Faculty of Applied Sciences website for the most up-to-date and accurate information.\n",
      "\n",
      "Documents:\n",
      "doc_id: 1709\n",
      "URL: https://vancouver.calendar.ubc.ca/faculties-colleges-and-schools/faculty-applied-science\n",
      "Titles: ['The Faculty of Applied Science']\n",
      "Text:\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Links:[]\n",
      "Relevance: The document is relevant to the question. It appears to be a list of specializations offered by the Faculty of Applied Sciences.\n",
      "doc_id: 1711\n",
      "URL: https://vancouver.calendar.ubc.ca/faculties-colleges-and-schools/faculty-applied-science\n",
      "Titles: ['The Faculty of Applied Science', 'Contents']\n",
      "Text:\n",
      "\n",
      "  18. Master of Health Leadership and Policy in Seniors Care \n",
      "  19. Academic Staff\n",
      "\n",
      "\n",
      "Links:['https://vancouver.calendar.ubc.ca/node/14514', 'https://vancouver.calendar.ubc.ca/node/14494']\n",
      "Relevance: The document appears to be a list of specializations or programs offered by the Faculty of Applied Sciences. The document mentions a Master of Health Leadership and Policy in Seniors Care, which is a specialization in the field of healthcare. This document is relevant to the question as it provides information on the specializations offered by the Faculty of Applied Sciences, which is what the question is asking about.\n",
      "doc_id: 1710\n",
      "URL: https://vancouver.calendar.ubc.ca/faculties-colleges-and-schools/faculty-applied-science\n",
      "Titles: ['The Faculty of Applied Science', 'Contents']\n",
      "Text:\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "  1. Introduction \n",
      "  2. Bachelor of Applied Science \n",
      "  3. Co-operative Education Program \n",
      "  4. Professional Associations \n",
      "  5. Joint UNBC/UBC Program: Environmental Engineering \n",
      "  6. Post-Baccalaureate Certificate in Mechanical Engineering in the BC Context \n",
      "  7. Graduate Certificates Programs \n",
      "  8. Master of Engineering \n",
      "  9. Master of Engineering Leadership in Advanced Materials Manufacturing \n",
      "  10. Master of Engineering Leadership in Clean Energy Engineering \n",
      "  11. Master of Engineering Leadership in Dependable Software Systems \n",
      "  12. Master of Engineering Leadership in High Performance Buildings \n",
      "  13. Master of Engineering Leadership in Integrated Water Management \n",
      "  14. Master of Engineering Leadership in Naval Architecture and Marine Engineering \n",
      "  15. Master of Engineering Leadership in Sustainable Process Engineering \n",
      "  16. Master of Engineering Leadership in Urban Systems \n",
      "  17. Master of Health Leadership and Policy in Clinical Education\n",
      "Links:['https://vancouver.calendar.ubc.ca/node/14466', 'https://vancouver.calendar.ubc.ca/node/14467', 'https://vancouver.calendar.ubc.ca/node/14515', 'https://vancouver.calendar.ubc.ca/node/14493', 'https://vancouver.calendar.ubc.ca/node/14505', 'https://vancouver.calendar.ubc.ca/node/53117', 'https://vancouver.calendar.ubc.ca/node/14464', 'https://vancouver.calendar.ubc.ca/node/14506', 'https://vancouver.calendar.ubc.ca/node/14507', 'https://vancouver.calendar.ubc.ca/node/14508', 'https://vancouver.calendar.ubc.ca/node/14513', 'https://vancouver.calendar.ubc.ca/node/14516', 'https://vancouver.calendar.ubc.ca/node/14512', 'https://vancouver.calendar.ubc.ca/node/14509', 'https://vancouver.calendar.ubc.ca/node/14511', 'https://vancouver.calendar.ubc.ca/node/14510', 'https://vancouver.calendar.ubc.ca/node/14517']\n",
      "Relevance: \n",
      "doc_id: 14086\n",
      "URL: https://science.ubc.ca/students/specialization-introduction\n",
      "Titles: ['BSc Specialization Application: Introduction', 'Faculty of Science']\n",
      "Text:\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Office of the Dean, Earth Sciences Building  \n",
      "21782207 Main Mall  \n",
      "Vancouver, BC Canada  \n",
      "V6T 1Z4 \n",
      "\n",
      "  -   -   -   -   - \n",
      "\n",
      "  - Emergency Procedures \n",
      "  - Terms of Use \n",
      "  - UBC Copyright \n",
      "  - Accessibility \n",
      "\n",
      " UBC Crest The official logo of the University of British Columbia. Urgent Message An exclamation mark in a speech bubble. Arrow An arrow indicating direction. Arrow in Circle An arrow indicating direction. A bookmark An ribbon to indicate a special marker. Calendar A calendar. Caret An arrowhead indicating direction. Time A clock. Chats Two speech clouds. External link An arrow pointing up and to the right. Facebook The logo for the Facebook social media service. A Facemask The medical facemask. Information The letter 'i' in a circle. Instagram The logo for the Instagram social media service. Linkedin The logo for the LinkedIn social media service. Lock, closed A closed padlock. Lock, open An open padlock. Location Pin A map location pin. Mail An envelope.\n",
      "Links:['https://ca.linkedin.com/showcase/ubc-science', 'https://www.ubc.ca/landing/emergencyprocedures.html', 'https://www.ubc.ca/site/legal.html', 'https://copyright.ubc.ca', 'https://www.ubc.ca/accessibility/']\n",
      "Relevance: The document appears to be the footer of a webpage from the University of British Columbia's Faculty of Applied Sciences. It does not provide information on the specializations in the Faculty of Applied Sciences. Therefore, it is not relevant to the question.\n",
      "doc_id: 14087\n",
      "URL: https://science.ubc.ca/students/specialization-introduction\n",
      "Titles: ['BSc Specialization Application: Introduction', 'Faculty of Science']\n",
      "Text:\n",
      "Mask A protective face mask. Menu Three horizontal lines indicating a menu. Minus A minus sign. Money A money bill. Telephone An antique telephone. Plus A plus symbol indicating more or the ability to add. RSS Curved lines indicating information transfer. Search A magnifying glass. Arrow indicating share action A directional arrow. Twitter The logo for the Twitter social media service. Youtube The logo for the YouTube video sharing service.\n",
      "\n",
      "Links:['https://ca.linkedin.com/showcase/ubc-science']\n",
      "Relevance: This document is not relevant to the question. The provided document appears to be a menu or a set of icons, but it does not provide information about the specializations in the Faculty of Applied Sciences.\n",
      "doc_id: 10023\n",
      "URL: https://vancouver.calendar.ubc.ca/faculties-colleges-and-schools/faculty-applied-science/bachelor-applied-science/introduction\n",
      "Titles: ['Introduction']\n",
      "Text:\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "The Faculty offers programs of undergraduate study leading to the Bachelor of Applied Science in the following areas of engineering: Biomedical Engineering, Chemical Engineering, Chemical and Biological Engineering, Civil Engineering, Computer Engineering, Electrical Engineering, Engineering Physics, Environmental Engineering, Geological Engineering, Integrated Engineering, Manufacturing Engineering, Materials Engineering, Mechanical Engineering, and Mining Engineering. It also offers the Bachelor of Applied Science in Environmental Engineering as a joint program with the University of Northern British Columbia. \n",
      "\n",
      " The Faculty of Applied Science admits suitably qualified applicants directly from secondary school into first-year engineering. These students will normally complete the Bachelor of Applied Science in four years of academic study, except in the case of the Engineering Physics program, which requires five years' study.\n",
      "Links:[]\n",
      "Relevance: The document is relevant to the question as it provides information about the specializations offered by the Faculty of Applied Sciences, specifically in the area of engineering. It lists various programs and their duration, which answers the question about the specializations in the Faculty of Applied Sciences.\n",
      "doc_id: 10569\n",
      "URL: https://vancouver.calendar.ubc.ca/faculties-colleges-and-schools/faculty-education/diploma-education#3411\n",
      "Titles: ['Diploma in Education', 'Fields of Specialization']\n",
      "Text:\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Fields of specialization include adult education, art education, business education, computing studies education, curriculum and pedagogy, early years education, teaching English as a second language, guidance studies, health education, health and wellness, home economics education, infant development and supported child development, language and literacy education, mathematics education, mathematics and science education, outdoor environmental education, physical education, secondary education, science education, social studies, special education, teacher librarianship, technology studies education, and visual and performing arts in education.\n",
      "\n",
      "Links:[]\n",
      "Relevance: The document is relevant to the question as it lists various specializations in the Faculty of Applied Sciences, which includes fields such as education, computing studies, health education, and more.\n",
      "doc_id: 13536\n",
      "URL: https://science.ubc.ca/students/first-year-courses\n",
      "Titles: ['Choosing Your Courses in First Year Science', 'Step 1: Determine Your Areas of Interest', 'What is a specialization?']\n",
      "Text:\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "A specialization is also known as a major. By the end of first year, every UBC Science undergraduate student must choose a specific area of study. Throughout the rest of your time at UBC, youll complete courses within that area of study. As a first-year student planning your timetable, consider areas of interest (potential specializations) and build your timetable based on pre-requisites needed for your intended specialization. Be sure to read the related and important information on the UBC Academic Calendar. Weve included a link on the right.\n",
      "\n",
      "Links:[]\n",
      "Relevance: The document is relevant to the question as it discusses the concept of specializations in the Faculty of Applied Sciences at UBC, which is directly related to the topic of the question.\n",
      "doc_id: 14084\n",
      "URL: https://science.ubc.ca/students/specialization-introduction\n",
      "Titles: ['BSc Specialization Application: Introduction', 'What happens if I dont apply for a specialization?']\n",
      "Text:\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Eligible students are required to apply for a specialization. Students with specializations experience the following advantages: \n",
      "\n",
      "  - Since departments prioritize course seats for students in their own specializations, students without a specialization may have a harder time getting into courses. \n",
      "  - Only students with specializations may apply to department specialization admission processes. For example, you cannot apply to some honours programs without an existing specialization. \n",
      "\n",
      "Students who do not obtain a specialization before the end of the winter session in which they have completed 48 credits of course work will be assigned a specialization by the Faculty of Science.Step 2 - Frequently Asked Questions\n",
      "\n",
      "Links:['https://science.ubc.ca/students/degree/apply/faq']\n",
      "Relevance: The document is relevant to the question as it discusses specializations in the Faculty of Applied Sciences, specifically mentioning that eligible students need to apply for a specialization and the advantages of having one.\n",
      "doc_id: 13538\n",
      "URL: https://science.ubc.ca/students/first-year-courses\n",
      "Titles: ['Choosing Your Courses in First Year Science', 'Step 1: Determine Your Areas of Interest', 'UBC Academic Calendar (BSc)']\n",
      "Text:\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "UBC Science offers numerous areas of specializations for students. Visit the UBC Academic Calendar and scroll down to check out the details of your interested specialization(s). Each specialization Calendar entry will show you an overview of your degree, including the sample timetable you could have at each class standing.\n",
      "\n",
      "Links:['https://vancouver.calendar.ubc.ca/faculties-colleges-and-schools/faculty-science']\n",
      "Relevance: The document is relevant to the question as it provides information about the Faculty of Applied Sciences and the specializations offered by UBC Science.\n",
      "_________________________________________________________________________________________________________\n",
      "Additional Documents:\n",
      "answer_time: 4.568623065948486\n",
      "\n",
      "total_time: 12.855732679367065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = answer_prompt(\"What are all the specializations in the Faculty of Applied Sciences?\", 5)\n",
    "\n",
    "neat_print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
