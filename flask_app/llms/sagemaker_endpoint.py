from langchain import SagemakerEndpoint

class MySagemakerEndpoint(SagemakerEndpoint):
    """
    Sagemaker Endpoint wrapper that removes prompt text from the generated output
    """
    
    def _call(self, prompt: str, stop, run_manager,**kwargs) -> str:
        """Call out to Sagemaker inference endpoint.

        Args:
            prompt: The prompt to pass into the model.
            stop: Optional list of stop words to use when generating.

        Returns:
            The string generated by the model.
            Removes any prompt text from the output

        Example:
            .. code-block:: python

                response = se("Tell me a joke.")
        """
        generated_text = super()._call(prompt, stop, run_manager, **kwargs)
        if generated_text.startswith(prompt): 
            # If the model returned the prompt as well as generated text, remove the prompt
            generated_text = generated_text[len(prompt):]
        return generated_text